<!-- GNU TERRY PRATCHETT -->

<!DOCTYPE html>
<html lang="fr">

<head>
  <meta charset="utf-8" />
  <title>NER-Annotateur-Quenya</title>
  <link rel="stylesheet" href="style.css">
</head>

<body>
<!-- Navbar à gauche -->
  <div class="navbar">
      <a href="quenya.html">Extraction NER</a>
      <a href="pipeline_spacy.html">Pipepline Spacy</a>
      <a href="blstm_crf.html">BSLTM CRF</a>
      <a href="methodologie.html">Méthodologie</a>
      <a href="sources.html">Sources</a>
  </div>

<!--Conteneur principal -->
  <div class="main-content">
  <div class="blurred-content">
  <h1 border= 5px solid #3498db >Bi-directional LSTM CRF</h1>
  <p>
  La seconde méthode utilisée pour la création d'un outil de reconnaissanced d'entités nommées pour le Quenya a été trouvé dans un  <a href="https://aclanthology.org/P16-1101/">article</a>.</p> <p>Un <a href=" https://github.com/TheAnig/NER-LSTM-CNN-Pytorch/blob/master/Named_Entity_Recognition-LSTM-CNN-CRF-Tutorial.ipynb">tutoriel</a> sur l'architecture de ce modèle va de paire avec l'article.
  </p>

  <h2> Format des données d'entrées </h2>
    <p> <b> Corpus d'entrée</b> </p>
  <p>
    Le modèle attend trois fichiers (test, train, dev) au format tsv avec trois colonnes (le mot et deux colonnes avec les tags). Les documents sont séparés par des lignes : </p>
  <p> -DOCSTART- 0 NA </p>
   <p> Les phrases sont ensuite séparées avec des lignes vides.  </p>


<h2> Création des embeddings </h2>
<p> <b> Embeddings Complexes </b> </p>
<p> Les Tensors qui sont utilisés dans le model sont composés de représentations numériques (ID) uniques représentant chacun des mots, des tags et des characters. </p>

  <p> <b> Embeddings Glove </b> </p>
  <p>
    Pour completer les ID unique des mots, nous ajoutons des embeddings qui porteront plus d'informations.
    Dans l'article, les auteurs ont utilisé des embeddings pré-entrainés de Glove (6B.100d). Dans notre cas, nous avons pré-entrainé des embeddings glove avec la totalité de notre corpus sous le même format 100 dimensions.
  </p>

    <h2> Architecture du modèle </h2>

  <p> Ce modèle combine plusieurs processus afin de caputer des informations au niveau des caractères, des mots et des suites d'étiquettes. </p>

<p> <b>1. CNN (Caractéristiques au niveau des caractères) :</b> </p>
<p>
Un réseau de neurones convolutionnel (CNN) repère des caractéristiques morphologiques à partir des embeddings de caractères de chaque mot, prévenant les mots hors-vocabulaire et les structures morphologiques.
</p>

<p> <b> 2. Bi-LSTM (Représentations contextuelles au niveau des mots) : </b> </p>
<p> Un réseau Long Short-Term Memory bidirectionnel (Bi-LSTM) traite les embeddings de mots (allant de paires avec les représentations des caractères) dans les deux directions, capturant ainsi les dépendances à plus long terme dans la phrase.</p>


<p> <b> 3. CRF (relations entre un label et une chaîne) : </b> </p>
<p> La couche de Conditional Random Field (CRF) prend en compte les relations entre les étiquettes de sortie. Ce qui améliore la cohérence entre des séquences de labels prédites.</p>

<h2> Résultats du modèle </h2>
<p>Les paramètres que nous avons modifiés sont: </p>
<ul>
<li>Le retrait ou non des majuscules,</li>
<li>Les dimensions des embeddings des caractères. </li>
</ul>

<p>Nous utiliserons uniquement les embeddings glove que nous avons entrainé sur notre corpus. </p>
<p>Une fonction de ce programme permet de remplacer tous les chiffres en 0 mais nous n'en avons pas eu besoin.</p>
<p>Nous aurions pu modifiés de nombreux autres paramètres ou hyper-paramètres comme le nombre de <i> hidden units</i> dans chaque couche du LSTM <code>parameters['word_lstm_dim'] = 200</code>.</p>

<p></p>

<p><b>Modèle 1 :</b> </p>
<p> Le plus similaire à celui qui est dans l'article. </p>
<p>
<ul>
<li><b>Case :</b> <code>parameters['lower']  = True</code> </li>
<li><b>Caractères embeddings :</b> <code> parameters['char_dim'] = 30 </code> </li>
<li><b>Epochs :</b> <code>parameters['epoch'] = 50 </code> </li>
</ul>
</p>
<p>La mesure de ce premier modèle est de <b>0.6666666666666667 </b>. </p>

<p><b>Modèle 2 :</b> </p>
<p><ul>
<li><b>Case :</b> <code>parameters['lower']  = True</code> </li>
<li><b> Caractères embeddings :</b> <code> parameters['char_dim'] = 40 </code> </li>
<li><b>Epochs : </b><code>parameters['epoch'] = 50 </code> </li>
</ul></p>
<p>La mesure de ce deuxième modèle est de <b>0.8224299065420562</b>. </p>

<p><b>Modèle 3 :</b> </p>
<p><ul>
<li><b>Case :</b> <code>parameters['lower']  = False</code> </li>
<li><b> Caractères embeddings :</b> <code> parameters['char_dim'] = 40 </code> </li>
<li><b>Epochs : </b><code>parameters['epoch'] = 50 </code> </li>
</ul></p>
<p>La mesure de ce premier modèle est de <b>0.7766990291262136</b>. </p>

<h2>Résultats</h2>

<h3>Texte 1 - Tolkien : <em>Eldar ataformaiti</em></h3>

    <p> <span class="person">PERSON</span> &nbsp;&nbsp;&nbsp;&nbsp; <span class="location">LOC</span></p>

    <blockquote>
                <em><b>
                Eldar ataformaiti, epetai i hyarma ú ten ulca símaryassen.
                úsië, an cé mo quernë cendelë númenna, ve senya, i hyarma tentanë <span class="person">Melcorello</span>, ar cé mo formenna tentanes <span class="location">Amanna</span>.
                </b></em>
            </blockquote>

            <blockquote>
                <em>
                The Elves were ambidexters, consequently the left hand was not to them evil in their imaginations.
                On the contrary, for if one turned the face westward, as was usual, the left hand pointed away from Melkor, and if northwards, it pointed toward towards Aman.
                </em>
    </blockquote>

Le modèle ne relève aucune entité nommée dans cet exemple...

<h3>Texte 2 - Néo-Quenya : <em>Kelevala</em></h3>

            <blockquote>
                <em><b>
                San sinë Tarcildillon i etelehtaner cuilintar nórentava lantallo, Rómenna utúlier vë quenta ná mí Akallabeth.
                I canonta né <span class="person">Elendil Halla</span> ar yondoryat - <span class="person">Isildur</span> ar <span class="person">Anárion</span> - orórot Arfarazonwa ar neurot Elrossevai alalastaner <span class="person">Sauron</span> ar alaohtacarer Herunúmennar.
                Avánier Atalanter <span class="location">Númenórello</span> entë ar ilyë Tarcildi vorondar ciryainen.
                Sinë neri ner meletyë ar haryaner ciryar poldë ar hallë, nán raumo lantanë entennar ar amortanet nenamboinen tenna i lumbar, ar taltanentë  falassenna Endorwa vë sornor raumova.
                </b></em>
            </blockquote>

            <blockquote>
                <em>
                In that time those of the Númenóreans who were saved from destruction fled eastward,
                as is told in the Akallabêth. The chief of these were Elendil the Tall and his sons, Isildur and Anárion.
                Kinsmen of the King they were, descendants of Elros, but they had been unwilling to listen to Sauron, and had refused to make war on the Lords of the West.
                Manning their ships with all who remained faithful they forsook the land of Númenor ere ruin came upon it.
                They were mighty men and their ships were strong and tall, but the tempests overtook them, and they were borne aloft on hills of water even to the clouds, and they descended upon Middle-earth like birds of the storm.
            </blockquote>
                </em>

<div class="image-container", style="text-align:center">
                <img src="img/blstm_texte2.png" alt="NER Results for Tolkien Text">
            </div>

            <h3>Texte 3 - Néo-Quenya : <em>L'évangile selon Matthieu</em></h3>

             <blockquote>
                <em><b>
                Si <span class="person">Yoháno</span> vettie ná íre i Yúrar mentaner airimóli ar Levindeli <span class="location">Yerúsalemello</span> maquetien senna:
                “Man nalye?” Ar carampes pantave ar ua lalane, mal quente pantave: “Uan i <span class="person">Hristo</span>.” Ar maquentelte senna:
                “Tá mana? Ma nalye <span class="person">Elía</span>?” Ar eques: “Uan.” “Ma nalye i Erutercáno?” Ar hanquentes: “Lá!” Etta quentelte senna:
                “Man nalye? Lava men same hanquenta in mentaner me. Mana quetil pa imle?” Eques: “Nanye óma yamila i ravandasse:
                Cara i <span class="person">Héruo</span> malle téra! – tambe <span class="person">Yesaia i Erutercáno</span> quente.”
                </b></em>
            </blockquote>
            <blockquote>
                <em>
                This is the witness of John when the Jews sent some priests and Levites from Jerusalem to inquire of him:
                “Who are you?” And he spoke openly and did not deny [it], but said openly: “I am not the Christ.”
                And they asked him: “Then what? Are you Elijah?” And he said: “I am not.” “Are you the Prophet?” And he answered:
                “No!” Therefore they said to him: “Who are you? Let us have an answer for those who sent us. What do you say about yourself?”
                He said: “I am a voice crying in the desert: Make the Lord’s way straight! – as Isaiah the Prophet said.”
                </em>
            </blockquote>

            <div class="image-container", style="text-align:center">
                <img src="img/blstm_texte3.png" alt="NER Results for Kelevala">
            </div>

<p>Comme dans le modèle entrainé avec spacy, nous avons de meilleurs résultats quand la la casse n'est pas prise en compte.</p>
<p>Nous pouvons également observer qu'il est plus intéréssant pour nous d'avoir des embeddings de caractères plus grands. Le modèle utilisé comme modèle étant utilisé sur de l'anglais (une langue avec peu ou pas de diacritiques), une langue comme le Quenya aura beosin de plus de place pour représenter les caractères.</p>
<p>Pour ce qui est des entités, comme avec spacy la catégorie minoritaire des Lieux est moins bien reconnue.</p>

  </div>
  </div>
</body>


</html>

